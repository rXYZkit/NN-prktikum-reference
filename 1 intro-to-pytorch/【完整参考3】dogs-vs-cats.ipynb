{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Dog-Cat classification task and Transfer Learning(来自 CNN-Tutorial)   \n",
    "\n",
    "+ 使用ImageFolder加载数据   \n",
    "+ 使用ResNet做迁移学习\n",
    "\n",
    "如我们从讲座中学到的那样，在许多场景中我们希望重用一个已经训练过的模型，用于一个类似的任务(称之为target task)，因为   \n",
    "+ 原始模型使用大量数据(well-resource)进行训练，但在target task我们不具备这种条件。也许我们只有很少的(好的)数据用于目标任务(low-resource)，或者用于target task的数据位于原始任务的其他领域，或者两者都有……\n",
    "+ 也许原来的模型已经很好了，我们不想使用相同的架构，并且从零开始为target task训练它，可能从原始模型中提取的特征(features extracted from)对新target task有很好的效果。   \n",
    "\n",
    "在新的类似任务上使用已经训练过的模型进行任务（宽松地）称为**“迁移学习”**。 迁移学习是深度学习和机器学习中的重要概念。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1. Dog-Cat classification task\n",
    "首先，我们应该查看与CIFAR10类似的任务：Dog-Cat分类任务。 回顾CIFAR10任务：我们需要将32×32的彩色图像分类为10个不同的类别：飞机，汽车，鸟类，猫，鹿，狗，青蛙，马，船和卡车。 我们的Dog-Cat分类任务相似，但更为简单。它将在单独的数据集DogsvsCats上进行训练，该数据集是我从受欢迎的Kaggle的[Kaggle's DogsvsCat challenge](https://www.kaggle.com/c/dogs-vs-cats)中获取的(由于原始数据集用作这个challenge的数据，因此我没有test set的真实标签，所以下面我们将一些训练集分为了验证集和测试集-仅用于演示目的)。   \n",
    "与CIFAR10任务相比，此处的主要区别在于图像的分辨率不同：大多数图像不是正方形图像，并且大多数图像的分辨率比32×32大得多。 在馈入我们的网络之前，**我们需要将它们scale为32×32**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，您可以在此处下载zip文件：http://i13pc106.anthropomatik.kit.edu/~tha/teaching/dogs-vs-cats.zip。 然后将其上传到数据文件夹。 然后取消注释并运行以下命令以将其解压缩：\n",
    "+ 下载不了，我单独在kaggle下载了train的zip数据放到了目录下解压缩\n",
    "+ 训练之后(完成这个练习)将会把这个数据移动到数据仓库防止占用同步空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"Data/dogs-vs-cats.zip\",\"r\") as zip_ref:\n",
    "    # Extract to storage/ of Gradient (free persistent storage)\n",
    "    zip_ref.extractall(\"storage/Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 构建自定义数据集custom dataset:\n",
    "  + 查看文件目录知道图片是以这种名称保存的`cat.6089.jpg`\n",
    "  + 我们现在要提取出label  \n",
    "  \n",
    "  \n",
    "`label = int(path.split('.')[0] == 'dog')` 是指在`train=True`的情况下如果图片的名称是'dog'标签是1，如果不是(图像是cat)标签是0；否则所有图片的标签都是-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# One-hot encoding\n",
    "def one_hot_encoding(idx):\n",
    "    one_hot_array = np.zeros(10)\n",
    "    one_hot_array[idx] = 1\n",
    "    return one_hot_array\n",
    "\n",
    "# 解析raw数据函数-调用这个函数将返回image(PIL格式)和image的label(int，或者np.array)\n",
    "def parse_data(data_dir, path, train=True, one_hot=False):\n",
    "    # path 是指对任意一个path的图片\n",
    "    label = int(path.split('.')[0] == 'dog') if train else -1\n",
    "    # 把label独热编码\n",
    "    if one_hot:\n",
    "        label = np.array(map(one_hot_encoding, label))\n",
    "        \n",
    "    # 再返回PILimage 典型路径为 storage/Data/cat.6089.jpg\n",
    "    image = Image.open(os.path.join(data_dir, path))\n",
    "    return image, label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 先看使用pytorch自带的数据集的加载方法   \n",
    "```python\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='Data/',\n",
    "                                             train=True, \n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "```\n",
    "> 实现：我们可以自己去到cifar10的官网上把CIFAR-10 python version(http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz) 下载下来，然后解压为cifar-10-batches-py文件夹，并复制到相对目录`root=`下。(若设置download=True，则程序会自动从网上下载cifar10数据到相对目录`root=`下，但这样小伙伴们可能要等一个世纪了)，并对训练集进行加载(train=True)。\n",
    "\n",
    "下面简单讲解`root`、`train`、`download`、`transform`这四个参数\n",
    "\n",
    "1.`root`，表示cifar10数据的加载的相对目录   \n",
    "2.`train`，表示是否加载数据库的**训练集**，false的时候加载测试集   \n",
    "3.`download`，表示是否自动下载cifar数据集   \n",
    "4.`transform`，表示是否需要对数据进行预处理，None为不进行预处理\n",
    "\n",
    "+ **自己编加载数据集的函数，加载数据的用法**   \n",
    "```python\n",
    "train_dataset = MyDogCatData(main_dir,\n",
    "                        data_type=\"train\",\n",
    "                        transform=transform)\n",
    "```   \n",
    "\n",
    "\n",
    "+ 另外使用通用的数据加载器 ImageFolder   \n",
    "> \n",
    "```python\n",
    "data_dir = r'D:\\Jupyterlab_data\\Cat_Dog_data\\train' \n",
    "# TODO: create the ImageFolder\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载自定义数据集：当我们需要加载自己的数据集的时候也可以借鉴这种方法，只需要继承`torch.utils.data.Dataset`类并重写`__init__`,`__len__`,以及`__getitem__`这三个方法即可。这样组着的类可以直接作为参数传入到`torch.util.data.DataLoader`中去。   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例如CIFAR包含的构造函数的参数是：\n",
    "> https://pytorch.org/docs/stable/_modules/torchvision/datasets/cifar.html#CIFAR10   \n",
    "```python\n",
    " \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "\n",
    "Args:\n",
    "root (string): Root directory of dataset where directory ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n",
    "\n",
    "train (bool, optional): If True, creates dataset from training set, otherwise creates from test set.\n",
    "        \n",
    "transform (callable, optional): A function/transform that takes in an PIL image and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        \n",
    "target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n",
    "        \n",
    "download (bool, optional): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDogCatData(Dataset): ## 仿照class DatasetFolder(data.Dataset):\n",
    "    \"\"\"\n",
    "    写文本说明\n",
    "    Args:\n",
    "        main_dir (string): Directory with all the images.\n",
    "        data_type (\"train|valid|test\"): is it training/validation/testing data\n",
    "        transform (callable, optional): Optional transform to be applied on a sample.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, main_dir, data_type='train', transform=None, one_hot=False):\n",
    "        # 必须指定transform\n",
    "        self.transform = transform\n",
    "        \n",
    "        # self.train 是true还是false >>> # training set or test set\n",
    "        # >> 没太理解有啥用 见下说明\n",
    "        self.data_type = data_type\n",
    "        if self.data_type == 'train' or self.data_type == 'valid':\n",
    "            self._train = True\n",
    "        elif self.data_type == 'test':\n",
    "            self._train = False\n",
    "        else:\n",
    "            self._train = None\n",
    "            raise NameError('DataType (train|valid|test) provided incorrect. No data loaded!')\n",
    "            \n",
    "        # 读取数据 data_dir 实现读取这个路径 字符串'\\storage\\Data\\train'\n",
    "        # 返回[(image1, label1),(...)]\n",
    "        self.data = []\n",
    "        data_dir = os.path.join(main_dir, self.data_type)\n",
    "        \n",
    "        #self.data = [parse_data(data_dir, path, train=self._train) for path in os.listdir(data_dir)]\n",
    "        for path in os.listdir(data_dir):\n",
    "            image, label = parse_data(data_dir, path, train=self._train)\n",
    "            image = self.transform(image)\n",
    "            self.data.append((image, label))\n",
    "        \n",
    "        # 对数据执行transform/见下说明\n",
    "        # >>> 修正在for循环读取image时同步transform\n",
    "        # 举个transform的例子 self.transform=transforms.Reseze((32,32))\n",
    "        # 开始写错为 [self.transform(image, label)\n",
    "        \n",
    "        # self.data = [(self.transform(image), label) for (image, label) in self.data]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    # 如果在类中定义了__getitem__()方法，那么其实例对象dataset的（假设为P）\n",
    "    # 就可以这样P[key]取值。当实例对象做P[key]运算时，就会调用类中的__getitem__(key)方法\n",
    "    # 用来根据index查看数据可，需要注意的是 数据在生成实例的时候一般会指定transform\n",
    "    # 注意辨析\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, label) where image is class_index of the label class.\n",
    "        \"\"\"\n",
    "        # 得到image和其所属的label\n",
    "        # self.data 是一个元组列表\n",
    "        image, label = self.data[index]\n",
    "        return image, label\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "说明：\n",
    "\n",
    "```python\n",
    "self.data = []\n",
    "        data_dir = os.path.join(main_dir, self.data_type)\n",
    "        \n",
    "        #self.data = [parse_data(data_dir, path, train=self._train) for path in os.listdir(data_dir)]\n",
    "        for path in os.listdir(data_dir):\n",
    "            image, label = parse_data(data_dir, path)\n",
    "            self.data.append((image, label))\n",
    "        self.data = [(self.transform(image), label) for (image, label) in self.data]\n",
    "```\n",
    "报错：OSError: [Errno 24] Too many open files:\n",
    "> ---> 34             image, label = parse_data(data_dir, path)\n",
    "> 以restart 确实存在\n",
    "\n",
    "解决方法：\n",
    "```python\n",
    "#self.data = [parse_data(data_dir, path, train=self._train) for path in os.listdir(data_dir)]\n",
    "        for path in os.listdir(data_dir):\n",
    "            image, label = parse_data(data_dir, path, train=self._train)\n",
    "            image = self.transform(image)\n",
    "            self.data.append((image, label))\n",
    "```\n",
    "\n",
    "+ 将transform写在 for循环中，totensor起作用了？不是，注释掉仍然起作用，猜想是进行图片的transform会释放？？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "```python\n",
    "self.data = [parse_data(data_dir, path, train=self._train) \n",
    "             for path in os.listdir(data_dir)]\n",
    "```\n",
    "\n",
    "```python\n",
    "def parse_data(data_dir, path, train=True, one_hot=False):\n",
    "    # path 是指对任意一个path的图片\n",
    "    label = int(path.split('.')[0] == 'dog') if train else -1\n",
    "    # 把label独热编码\n",
    "    if one_hot:\n",
    "        label = np.array(map(one_hot_encoding, label))\n",
    "        \n",
    "    # 再返回PILimage 典型路径为 storage/Data/cat.6089.jpg\n",
    "    image = Image.open(os.path.join(data_dir, path))\n",
    "    return image, label \n",
    "```   \n",
    "\n",
    "则 `self.data` 将会返回[元组列表]， 每个元组是图像和它对应的label  \n",
    "+ 和官方文档中的 `def find_classes(dir):`+ `def make_dataset(dir, class_to_idx, extensions): ` 实现相同的功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样我们的**数据集就创建好了**，具体的使用方法：(在小数据集valid中使用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_valid = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
    "\n",
    "main_dir = r'C:\\Users\\123\\Desktop\\数据集仓库\\dogs-vs-cats'\n",
    "\n",
    "valid_dataset = MyDogCatData(main_dir, data_type='valid', transform=transform_valid)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=50, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_loader)) # 1是因为这个集合就放了10个图片，1个batch就读完了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 扩展\n",
    "\n",
    "[好文：PyTorch自定义数据集](https://www.cnblogs.com/picassooo/p/12846617.html)\n",
    "\n",
    "```python\n",
    "class DogVsCatDataset(Dataset):   # 创建一个叫做DogVsCatDataset的Dataset，继承自父类torch.utils.data.Dataset\n",
    "    def __init__(self, root_dir, train=True, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.img_path = os.listdir(self.root_dir)\n",
    "        if train:\n",
    "            self.img_path = list(filter(lambda x: int(x.split('.')[1]) < 10000, self.img_path))    # 划分训练集和验证集\n",
    "        else:\n",
    "            self.img_path = list(filter(lambda x: int(x.split('.')[1]) >= 10000, self.img_path))\n",
    "        self.transform = transform\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(os.path.join(self.root_dir, self.img_path[idx]))\n",
    "        label = 0 if self.img_path[idx].split('.')[0] == 'cat' else 1        # label, 猫为0，狗为1\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.from_numpy(np.array([label]))\n",
    "        return image, label\n",
    "```\n",
    "---\n",
    "### 一个小问题   \n",
    "他这里要求是：把猫狗数据集的其中前10000张猫的图片和10000张狗的图片作为训练集，把后面的2500张猫的图片和2500张狗的图片作为验证集。猫的label记为0，狗的label记为1。     \n",
    "\n",
    "+  `__init__`中的 `root_dir` 与 `transform` 与我们这里定义一样，但是我们还定义了 `data_type='train'` 这个参数，没太看懂有什么用。\n",
    "\n",
    "+ 这里通过 `train=True` 指向(分割已有数据集)得到训练数据集，反之 `train=False`得到验证数据集；\n",
    "\n",
    "+ 我们前面熟悉的是先得到`train_dataset`再自己分割，而这里是可以直接通过函数`DogVsCatDataset(..train=False,)` 获得 valid_dataset\n",
    "\n",
    "+ 这里 `self._train = True` -> `mage, label = parse_data(data_dir, path, train=self._train)` -> 最初的读取图像函数中   \n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "def parse_data(data_dir, path, train=True, one_hot=False):\n",
    "    label = int(path.split('.')[0] == 'dog') if train else -1\n",
    "    ...\n",
    "```\n",
    "\n",
    "+ 如果 设置`if self.data_type == 'train' or self.data_type == 'valid':` 则if train 就是 True，则可以得到解析的图片路径的图片的标签为0(dog)或1(非dog);\n",
    "+ 而只有我们在使用 `MyDogCatData(data_type='test)` 生成数据集时所有图片的label都是-1\n",
    "+ 这么做有什么意义？(因为没有完整完成这个练习尚不能确定)\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 迁移学习  \n",
    "\n",
    "有多种方法可以完成此任务的转移学习，例如\n",
    "1. 也许基于CIFAR10数据训练的model已经很好，使得我们不需要使用Dog-Cat数据训练了。即直接使用CIFAR10 ResNet模型输出狗和猫的分类概率，比较这个概率，然后将图像分配到概率更大的类别中。我们称这种简单的方法为: **inference**，因为我们在这里不训练任何东西，只需进行推理.\n",
    "\n",
    "2. 也许我们想使用 trained model 作为相同架构的良好起点(除了输出层，因为现在我们只有两个类，而不是十个)。以及不是对我们的相同的架构(例如ResNet)随机初始化参数, 而是使用通过CIFAR10数据训练模型的得到的参数(称为pretrained model), 再在新Dog-Cat数据集(称为 fine-tuning)**训练**, 然后使用 new model 做了分类。我们称这个方法为**fine-tuning**。   \n",
    "\n",
    "3. 也许我们ResNet的Residual blocks(包含卷积层)在捕获features方面是如此出色，我们只需要学习一些好的方法来在我们新的Dog-Cat任务中组合这些features. 我们可以通过保持使用CIFAR10训练后的model的层中所有其他参数（也称为冻结层）不变（最后一个完全连接的层负责合并提取的特征），并在新的Dog-Cat数据集上进行训练，来完成此操作。预计它将比 fine-tuning 方法快得多。 我们称这种**freeze方法**。   \n",
    "\n",
    "现在，我们将实现所有上述方法。对于以上方法，我们都需要知道如何 save and load the checkpoints(state_dict)。加载checkpoints:的方式有两种：使用模型的state_dict（包含模型的可学习参数），或使用具有完整信息的整个模型。\n",
    "下面是我认为对这两种方式最好的解释:https://www.kdnuggets.com/2019/03/deploy-pytorch-model-production.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 直接inference   \n",
    "+ 在大数据集train中导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32,32)),  # made it to 32x32\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "main_dir = r'C:\\Users\\123\\Desktop\\数据集仓库\\dogs-vs-cats'\n",
    "\n",
    "train_dataset = MyDogCatData(main_dir,\n",
    "                        data_type=\"train\",\n",
    "                        transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "备注：这里自定义读取数据集的时候，在`__init__()`中写读取图片的函数部分导致了读取速度很慢？别的是在`__getitem()__`中写的，是这个原因吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 迁移学习之直接使用ResNet，在本文出处CNN-Tutorial中ResNet是自己训练的，因为没有做那一部分，我们instead直接调用torchvision中的与训练网络\n",
    "+ 此处实现对valid_loader的模型预测精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to C:\\Users\\123/.cache\\torch\\hub\\checkpoints\\resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b519e4aa683b4a3aa7508bdb413815e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "ResNet = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.64%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#net_infer = ResNet().to(device)\n",
    "#net_infer.load_state_dict(torch.load('storage/resnet.pth'))\n",
    "net_infer = ResNet.to(device)\n",
    "\n",
    "net_infer.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for images, labels in valid_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net_infer(images)\n",
    "        \n",
    "        # Get the softmax output for dogs and cats\n",
    "        cat_probs = outputs[:,3]\n",
    "        dog_probs = outputs[:,5]\n",
    "        \n",
    "        # Compare and assign the class whose softmax output is larger\n",
    "        correct += torch.sum((dog_probs >= cat_probs) == labels.to(dtype=torch.uint8))\n",
    "        \n",
    "\n",
    "accuracy = int(correct.cpu().numpy()) * 100 / len(valid_dataset)\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 迁移学习之**Fine-tuning Method**      \n",
    "训练了什么？\n",
    "> 基于所有参数再使用猫狗数据集训练一遍，不冻结参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 定义网络\n",
    "> load 前面训练过的 resnet网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "num_epochs = 30\n",
    "learning_rate = 0.0001\n",
    "\n",
    "torch.manual_seed(1111)\n",
    "np.random.seed(1111)\n",
    "\n",
    "net_ft = torch.load('storage/resnet.ckpt')\n",
    "\n",
    "in_feats = net_ft.fc.in_features\n",
    "### 二分类\n",
    "net_ft.fc = nn.Linear(in_feats, 2)\n",
    "net_ft = net_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "new_optimizer = torch.optim.Adam(net_ft.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    val_running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = net_ft(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        new_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        new_optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        print (\"Epoch [{}/{}], Training Loss: {:.4f}\"\n",
    "               .format(epoch+1, num_epochs, loss.item()))\n",
    "            \n",
    "# Save the model checkpoint\n",
    "torch.save(net_ft.state_dict(), 'storage/resnet2.pth')\n",
    "torch.save(net_ft, 'storage/resnet2.ckpt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 第三种是冻结一部分参数 -- 在这里，我们通过将require_grad设置为False来访问和冻结所需的参数/层，并仅更新希望他们学习的参数。\n",
    "> 全连接层不冻结，会被 新的数据集训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "num_epochs = 30\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "torch.manual_seed(1111)\n",
    "\n",
    "net_fz = torch.load('storage/resnet.ckpt')\n",
    "\n",
    "# Freeze all the parameters,\n",
    "# excepts the last fc layer \n",
    "# (which will be added)\n",
    "for param in net_fz.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "in_feats = net_fz.fc.in_features\n",
    "net_fz.fc = nn.Linear(in_feats, 2)\n",
    "\n",
    "net_fz = net_fz.to(device)\n",
    "\n",
    "new_optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "new_optimizer = torch.optim.Adam(net_fz.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    val_running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = net_fz(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        new_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        new_optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        print (\"Epoch [{}/{}], Training Loss: {:.4f}\"\n",
    "               .format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(net_fz.state_dict(), 'storage/resnet3.pth')\n",
    "torch.save(net_fz, 'storage/resnet3.ckpt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这种情况下，冻结方法的性能不如微调，但其训练要快得多。在其他情况下将以更少的训练参数实现类似的效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**本节参考的是00中CNN-Tutorial中的后半部分，但没有学习Resnet部分，有时间可以进一步学习**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 将数据集移到数据仓库，防止占用同步内存。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
